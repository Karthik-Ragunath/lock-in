# ğŸ”’ Lock-In: Never Wait Silently for Code Again

Lock-In transforms Cursor's AI agent from a silent code generator into an active pair programmer. Instead of staring at a loading spinner, you hear the agent explain its reasoning in real-time and can ask questions mid-generation.

**Built with [mcp-use](https://mcp-use.com/)** â€” Connect Any LLM to Any MCP Server

## ğŸ¯ The Problem

When Cursor's agent generates code, you wait 30-60 seconds in silence:
- âŒ No idea what it's thinking
- âŒ Can't course-correct early
- âŒ Wasted time feeling disconnected
- âŒ Miss learning opportunities

## âœ¨ The Solution

Lock-In gives Cursor's agent a voice:
- âœ… Hear reasoning in real-time ("I'm checking your auth setup...")
- âœ… Ask questions mid-generation ("Should we use JWT or sessions?")
- âœ… Catch mistakes before code is written
- âœ… Learn WHY decisions are made
- âœ… Stay engaged and "locked in" to the process

## ğŸ¥ Demo

**Old way:**
```
User: "Add authentication to my API"
[30 seconds of loading spinner]
[Code appears]
```

**Lock-In way:**
```
User: "Add authentication to my API"
Agent: "Alright, let me think about authentication for your API..."
Agent: "I'm checking your existing user model... I see you have password hashing already, good."
User: "Should we use JWT or sessions?"
Agent: "Great question! Since this is a REST API, JWT tokens would be better for stateless auth..."
Agent: "Now I'm creating the auth middleware file..."
[Code appears with full understanding of decisions]
```

## ğŸš€ Quick Start

```bash
# 1. Setup
cd lock-in
chmod +x scripts/setup.sh
./scripts/setup.sh

# 2. Add API keys to .env
# Edit .env with your Cartesia API key

# 3. Run the MCP Server (HTTP mode for testing)
./scripts/run.sh mcp-http

# 4. Test with MCP Inspector
npx @modelcontextprotocol/inspector --transport http --server-url http://localhost:8000/mcp

# 5. Or run everything (voice agent + MCP server + audio client)
./scripts/run.sh all
```

### Testing the MCP Server

The MCP server runs on `http://localhost:8000` with these endpoints:
- `/mcp` â€” MCP protocol endpoint (Streamable HTTP)
- `/openmcp.json` â€” OpenMCP schema
- `/inspector` â€” Built-in inspector UI
- `/docs` â€” API documentation

```bash
# Test with curl
curl http://localhost:8000/openmcp.json | jq .tools

# Test with MCP Inspector (local)
npx @modelcontextprotocol/inspector --transport http --server-url http://localhost:8000/mcp

# Test with ngrok (for remote access)
ngrok http 8000
# Then use the ngrok URL in MCP Inspector web UI
```

## ğŸ—ï¸ Architecture

```
Cursor Agent (generating code)
    â†“ (reasoning traces via MCP tools)
Lock-In MCP Server (mcp-use, port 8000)
    â†“ (narration text via WebSocket)
Voice Agent (Pipecat pipeline, port 8765)
    â†“ (TTS via Cartesia, protobuf frames)
Audio Client (browser, connects to port 8765)
    â†“
User's Speakers ğŸ”Š

User's Microphone ğŸ¤
    â†“ (captured by Audio Client)
Voice Agent (STT via Cartesia)
    â†“ (question via WebSocket)
MCP Server (answers using session context)
    â†“ (answer text)
Voice Agent â†’ Audio Client â†’ User's Speakers
```

### MCP Server Modes

The MCP server supports two transport modes:

| Mode | Command | Use Case |
|------|---------|----------|
| **HTTP** | `./scripts/run.sh mcp-http` | Web clients, MCP Inspector, ChatGPT, Claude |
| **stdio** | `./scripts/run.sh mcp` | Cursor IDE, Claude Desktop |

### Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VOICE AGENT                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  User Audio Input (microphone)                         â”‚
â”‚         â†“                                               â”‚
â”‚  Cartesia STT (speech â†’ text)                          â”‚
â”‚         â†“                                               â”‚
â”‚  UserQuestionHandler (detect questions)                â”‚
â”‚         â†“                                               â”‚
â”‚  NarrationInjector (queue + inject narration text)     â”‚
â”‚         â†“                                               â”‚
â”‚  Cartesia TTS (text â†’ speech)                          â”‚
â”‚         â†“                                               â”‚
â”‚  User Audio Output (speakers)                          â”‚
â”‚                                                         â”‚
â”‚  â† MCP Server sends narration/answers via WebSocket â†’  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
lock-in/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ SETUP.md                       # Detailed setup instructions
â”œâ”€â”€ COMMANDS.md                    # All commands reference
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                   # Automated setup script
â”‚   â””â”€â”€ run.sh                     # Multi-command run script
â”‚
â”œâ”€â”€ audio_client/
â”‚   â””â”€â”€ index.html                 # Browser audio client (WebSocket + protobuf)
â”‚
â”œâ”€â”€ mcp_server/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py                  # MCP server with tools (mcp-use SDK)
â”‚   â”œâ”€â”€ trace_listener.py          # Parse Cursor agent traces
â”‚   â”œâ”€â”€ narration_generator.py     # Convert traces to natural speech
â”‚   â”œâ”€â”€ context_manager.py         # Session context for Q&A
â”‚   â””â”€â”€ models.py                  # Pydantic data models
â”‚
â”œâ”€â”€ voice_agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py                   # Main voice agent orchestrator
â”‚   â”œâ”€â”€ config.py                  # Pydantic Settings configuration
â”‚   â””â”€â”€ pipeline.py                # Pipecat pipeline (STTâ†’LLMâ†’TTS)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_mcp_server.py         # MCP server component tests
â”‚   â”œâ”€â”€ test_voice_agent.py        # Voice agent component tests
â”‚   â””â”€â”€ test_integration.py        # Integration tests
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ example_traces.json        # Sample reasoning traces
    â””â”€â”€ test_narration.py          # Standalone narration demo
```

## ğŸ› ï¸ Tech Stack

- **[mcp-use](https://mcp-use.com/)** â€” MCP server SDK for Python (Streamable HTTP + stdio)
- **[Pipecat](https://github.com/pipecat-ai/pipecat)** â€” Voice pipeline orchestration
- **[Cartesia](https://cartesia.ai/)** â€” Ultra-low latency TTS/STT (< 500ms)
- **[MCP](https://modelcontextprotocol.io/)** â€” Model Context Protocol for Cursor integration
- **[Pydantic](https://docs.pydantic.dev/)** â€” Type-safe configuration and models
- **[Loguru](https://github.com/Delgan/loguru)** â€” Structured logging

## ğŸ¤ Example Narrations

**Planning Phase:**
> "Okay, so you want authentication. I'm thinking JWT tokens since this is a REST API. Let me plan out what files we'll need to touch."

**Analyzing Phase:**
> "I'm looking at your existing user model in models/user.py. I see you already have password hashing, that's good."

**Implementing Phase:**
> "Now I'm creating auth_middleware.py. Writing the verify_token function for protected routes..."

**Debugging Phase:**
> "Hmm, I noticed your token expiry is set to 15 minutes â€” that might be too short for development."

**Testing Phase:**
> "Let me verify this works... Running a quick check on the auth flow."

## ğŸ”Š Audio Client

The audio client is a browser-based frontend that connects to the voice agent's WebSocket on port 8765. It receives protobuf-encoded audio frames from the Pipecat pipeline and plays them through your speakers. Optionally, it captures microphone audio for the speech-to-text question flow.

```bash
# Serve the audio client (default port 8080)
./scripts/run.sh client

# Or specify a custom port
./scripts/run.sh client 9000

# Or start everything at once (voice agent + MCP server + audio client)
./scripts/run.sh all
```

Then open `http://localhost:8080` (or `http://<server-ip>:8080` from another machine), and click **Connect**.

## ğŸ”§ Configuration

Customize narration style, voice, speed, and more in `.env`:

```bash
# Use a different Cartesia voice
CARTESIA_VOICE_ID=your_preferred_voice_id

# Adjust narration speed (1.0 = normal, 1.2 = faster)
NARRATION_SPEED=1.1

# Enable/disable user interruptions
ENABLE_INTERRUPTIONS=true

# Set log level
LOG_LEVEL=DEBUG
```

See `.env.example` for all available settings.

## ğŸ“š Documentation

- [Setup Guide](SETUP.md) â€” Detailed setup and Cursor integration instructions
- [Commands Reference](COMMANDS.md) â€” All commands and usage patterns

## ğŸ§ª Testing

```bash
# Run all tests
./scripts/run.sh test

# Run with coverage
./scripts/run.sh test-coverage

# Run a specific test file
PYTHONPATH=. pytest tests/test_mcp_server.py -v
```

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- **[mcp-use](https://mcp-use.com/)** for the MCP server SDK
- [Anthropic](https://anthropic.com/) for MCP
- [Pipecat / Daily](https://www.pipecat.ai/) for voice infrastructure
- [Cartesia](https://cartesia.ai/) for low-latency TTS/STT
- [Cursor](https://cursor.com/) for the agent-trace spec
